{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import total_ordering\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import string\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'ϔ': 0, 's': 1, 'j': 2, '\\x0c': 3, 'ß': 4, 'k': 5, 'ϋ': 6, '}': 7, '7': 8, ')': 9, 'l': 10, '>': 11, \n",
    "#  'ꮪ': 12, 'w': 13, 'v': 14, ']': 15, '1': 16, 'ⅳ': 17, '\\x08': 18, '♦': 19, 'y': 20, '!': 21, '/': 22, \n",
    "#  '|': 23, '$': 24, ',': 25, 'ς': 26, '_': 27, 'z': 28, 'ꭲ': 29, '*': 30, 't': 31, '4': 32, '¹': 33, \n",
    "#  '[': 34, 'σ': 35, '∞': 36, 'b': 37, 'a': 38, '+': 39, '(': 40, '9': 41, '\\u1680': 42, 'h': 43, '?': 44, \n",
    "#  'ı': 45, 'm': 46, '0': 47, '\"': 48, 'ꮢ': 49, ':': 50, '໐': 51, 'u': 52, '6': 53, '%': 54, 'å': 55, \n",
    "#  'é': 56, '3': 57, '£': 58, 'p': 59, '#': 60, '.': 61, 'ü': 62, '8': 63, '@': 64, 'g': 65, 'i': 66, \n",
    "#  'x': 67, 'ዐ': 68, '０': 69, '5': 70, 'd': 71, '\\\\': 72, '2': 73, 'ſ': 74, 'ꮅ': 75, 'π': 76, 'e': 77, \n",
    "#  '-': 78, '<': 79, ';': 80, '=': 81, '&': 82, 'ﬁ': 83, '~': 84, '\\ufeff': 85, 'r': 86, '\\t': 87, \n",
    "#  '\\x00': 88, 'ꮛ': 89, '€': 90, 'n': 91, '{': 92, '\\n': 93, '`': 94, 'а': 95, ' ': 96, 'o': 97, 'c': 98, \n",
    "#  '^': 99, 'q': 100, \"'\": 101, 'f': 102}\n",
    "\n",
    "specials = ['\\n', '}', ')', '>', ']', '!', '/', '|', '$', ',', '_', '*', '?', '\"', ':', '%', '@', '.', '#', '\\\\', '\\t', '~', '&', '=', ';', '<', '-', '{', ' ', '^', \"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [join('annotated_rfcs/', f) for f in listdir('annotated_rfcs/') if isfile(join('annotated_rfcs/', f))]\n",
    "\n",
    "window = 5\n",
    "\n",
    "label_dict = { 'onr_rfcclass_nlt' : 0, 'onr_rfcclass_strdef' : 1, 'onr_rfcclass_msgStructure' : 2,\n",
    "'onr_rfcclass_dataflow' : 3,\n",
    "'onr_rfcclass_topologyDiag' : 4,\n",
    "'onr_rfcclass_table' : 5,\n",
    "'onr_rfcclass_stateTD' : 6,\n",
    "'onr_rfcclass_cs' : 7,\n",
    "'onr_rfcclass_protocolLayerDiag' : 8,\n",
    "'onr_rfcclass_caption' : 9,\n",
    "'onr_rfcclass_headers' : 10,\n",
    "'onr_rfcclass_toc' : 11,\n",
    "'onr_rfcclass_lex_spec' : 12 }\n",
    "\n",
    "# for k in label_dict.keys():\n",
    "#     label_dict[k]-=1\n",
    "# print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_window(w):\n",
    "    # print('w:',len(w)) \n",
    "    lst = []\n",
    "    for k in w:\n",
    "        lst.append([x for x in k])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(onlyfiles, train=True):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for r in onlyfiles:\n",
    "        if train and r == 'annotated_rfcs/mqtt.txt':\n",
    "            continue\n",
    "        print('processing :', r)\n",
    "        with open(r,  encoding=\"utf8\", errors='ignore') as rfh:\n",
    "            lines = rfh.readlines()\n",
    "            cur_tag = 'onr_rfcclass_nlt'\n",
    "            cur_label = label_dict[cur_tag]\n",
    "            for i,l in enumerate(lines):\n",
    "                if l=='\\n':\n",
    "#                     print('yowzaa!!')\n",
    "                    continue\n",
    "                if 'onr_rfcclass' in l:\n",
    "                    if 'onr_rfcclass_references_start' in l:\n",
    "                        break\n",
    "                    if l.startswith('<end_'):\n",
    "                        cur_tag = 'onr_rfcclass_nlt'\n",
    "                        cur_label = label_dict[cur_tag]\n",
    "                        continue\n",
    "                    else:\n",
    "                        cur_tag = l.strip()[1:-1]\n",
    "                        # print(cur_tag)\n",
    "                        cur_label = label_dict[cur_tag]\n",
    "                        continue\n",
    "                if i<=window: # lines before the window'th line\n",
    "                    lst = process_window(lines[i:i+window+1])\n",
    "                    smpl = [['a' for _ in range(50)] for _ in range(window)] + lst\n",
    "                    # print(len(smpl))\n",
    "                    assert len(smpl)==2*window+1\n",
    "                elif i==len(lines)-1:\n",
    "                    lst = process_window(lines[i-window:i+1])\n",
    "                    smpl = lst + [['a' for _ in range(50)] for _ in range(window)]\n",
    "                    # print(len(smpl))\n",
    "                    assert len(smpl)==2*window+1\n",
    "                else:\n",
    "                    smpl = process_window(lines[i-window:i+1]) + process_window(lines[i+1:i+window+1])\n",
    "                    # print(len(smpl))\n",
    "                    assert len(smpl)==2*window+1\n",
    "                samples.append(smpl)\n",
    "                labels.append(cur_label)\n",
    "    for _ in range(window):\n",
    "        samples.pop()\n",
    "        labels.pop()\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing : annotated_rfcs/rfc2131.txt\n",
      "processing : annotated_rfcs/rfc1035.txt\n",
      "processing : annotated_rfcs/rfc1661.txt\n",
      "processing : annotated_rfcs/rfc2616.txt\n",
      "processing : annotated_rfcs/rfc1001.txt\n"
     ]
    }
   ],
   "source": [
    "samples, labels = make(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing : annotated_rfcs/mqtt.txt\n"
     ]
    }
   ],
   "source": [
    "samples_mqtt, labels_mqtt = make(['annotated_rfcs/mqtt.txt'], train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "14194\n"
     ]
    }
   ],
   "source": [
    "print(len(samples_mqtt))\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in samples[len(samples)//2]:\n",
    "#     print(''.join(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC character bookkeepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of rfc line: 82\n"
     ]
    }
   ],
   "source": [
    "# get max line in RFCs\n",
    "onlyfiles = [join('../rfcs', f) for f in listdir('../rfcs') if isfile(join('../rfcs', f))]\n",
    "length_max = []\n",
    "for r in onlyfiles:\n",
    "    with open(r,  encoding=\"utf8\", errors='ignore') as rfh:\n",
    "        lines = rfh.readlines()\n",
    "        for l in lines:\n",
    "            length_max.append([l, len(l)])\n",
    "#ascending\n",
    "length_max = sorted(length_max, key=lambda x:x[1], reverse=True)\n",
    "# extract starting from the third element\n",
    "\n",
    "def get_char_vocab():\n",
    "    max_set = set()\n",
    "    onlyfiles = [join('../rfcs', f) for f in listdir('../rfcs') if isfile(join('../rfcs', f))]\n",
    "    for r in onlyfiles:\n",
    "        with open(r,  encoding=\"utf8\", errors='ignore') as rfh:\n",
    "            lines = rfh.readlines()\n",
    "            for l in lines:\n",
    "                l = l.lower()\n",
    "                l = set(l)\n",
    "                max_set = max_set.union(l)\n",
    "    return max_set\n",
    "\n",
    "print('max length of rfc line:', length_max[2][1])\n",
    "\n",
    "# vocab is the set of all chars in RFCs (mentioned above)\n",
    "# need to filter down to lowercase alphabets and chosen special characters\n",
    "vocab = get_char_vocab()\n",
    "\n",
    "# allowed = list(string.ascii_lowercase) + [str(x) for x in range(10)] + specials\n",
    "allowed = ['char'] + ['digit'] + specials\n",
    "# allowed = ['char'] + ['digit'] + ['specials']\n",
    "\n",
    "num_feat = len(allowed)+1\n",
    "\n",
    "char_to_idx = {}\n",
    "idx_to_char = {}\n",
    "for i,e in enumerate(allowed):\n",
    "    # allowed chars get an integer\n",
    "    # all others get unknown (idx = len(allowed))\n",
    "    char_to_idx[e] = i\n",
    "    idx_to_char[i] = e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'char', 1: 'digit', 2: '\\n', 3: '}', 4: ')', 5: '>', 6: ']', 7: '!', 8: '/', 9: '|', 10: '$', 11: ',', 12: '_', 13: '*', 14: '?', 15: '\"', 16: ':', 17: '%', 18: '@', 19: '.', 20: '#', 21: '\\\\', 22: '\\t', 23: '~', 24: '&', 25: '=', 26: ';', 27: '<', 28: '-', 29: '{', 30: ' ', 31: '^', 32: \"'\", 33: 'å'}\n"
     ]
    }
   ],
   "source": [
    "idx_to_char[len(allowed)] = 'å'\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of blank lines to total lines: 0.226581013744604\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "c=0\n",
    "for s in samples:\n",
    "    for l in s:\n",
    "        c+=1\n",
    "        if l==['\\n']:\n",
    "            cnt+=1\n",
    "print('ratio of blank lines to total lines:', cnt/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(samples):\n",
    "    for j,v in enumerate(e):\n",
    "        if v==['\\n']:\n",
    "            samples[i][j]=['\\n']*length_max[2][1]\n",
    "\n",
    "for i,e in enumerate(samples_mqtt):\n",
    "    for j,v in enumerate(e):\n",
    "        if v==['\\n']:\n",
    "            samples_mqtt[i][j]=['\\n']*length_max[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build samples : with context this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_maxlen = length_max[2][1]\n",
    "def create_samples(samples):\n",
    "    '''\n",
    "    read each sample, convert line to list of integers (indexes) using char_to_idx\n",
    "    join the resulting vector to master array\n",
    "    return array\n",
    "    '''\n",
    "    data = []\n",
    "    for s in samples:\n",
    "        mini_data = []\n",
    "        for line_list in s:\n",
    "            ll = []\n",
    "            cur_len = len(line_list)\n",
    "            for char in line_list:\n",
    "                if char.isalpha():\n",
    "                    ll.append(char_to_idx['char'])\n",
    "#                     ll.append(char_to_idx[char])\n",
    "                elif char.isdigit():\n",
    "                    ll.append(char_to_idx['digit'])\n",
    "#                     ll.append(char_to_idx[digit])\n",
    "                elif char in specials:\n",
    "                    ll.append(char_to_idx[char])\n",
    "#                     ll.append(char_to_idx['specials'])\n",
    "                else:\n",
    "                    ll.append(len(allowed))\n",
    "            # pad sequences shorter than _maxlen\n",
    "            pad = _maxlen - cur_len\n",
    "            for _ in range(pad):\n",
    "                ll.append(len(allowed))\n",
    "            mini_data.append(ll)\n",
    "        data.append(mini_data)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_samples(samples)\n",
    "y = np.array(labels)\n",
    "\n",
    "X_mqtt = create_samples(samples_mqtt)\n",
    "y_mqtt = np.array(labels_mqtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14194, 11, 82)\n",
      "(14194,)\n",
      "(1279, 11, 82)\n",
      "(1279,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_mqtt.shape)\n",
    "print(y_mqtt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_one_hot(idx):\n",
    "    res = np.zeros((1,num_feat))\n",
    "    res[0][idx] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14194, 11, 82, 34)\n"
     ]
    }
   ],
   "source": [
    "vector_len = len(allowed)+1\n",
    "big_mat = []\n",
    "for sample in X: # (5,82)\n",
    "    mat = []\n",
    "    for s in sample: # (82,)\n",
    "        idx_mat = []\n",
    "        for idx in s:\n",
    "            cand = np.zeros((vector_len))\n",
    "            cand[idx] = 1 #(1x33)\n",
    "            idx_mat.append(cand)\n",
    "        mat.append(idx_mat)\n",
    "    big_mat.append(np.array(mat))\n",
    "    \n",
    "big_mat = np.array(big_mat)\n",
    "print(big_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 11, 82, 34)\n"
     ]
    }
   ],
   "source": [
    "big_mat_mqtt = []\n",
    "for sample in X_mqtt: # (5,82)\n",
    "    mat = []\n",
    "    for s in sample: # (82,)\n",
    "        idx_mat = []\n",
    "        for idx in s:\n",
    "            cand = np.zeros((vector_len))\n",
    "            cand[idx] = 1 #(1x33)\n",
    "            idx_mat.append(cand)\n",
    "        mat.append(idx_mat)\n",
    "    big_mat_mqtt.append(np.array(mat))\n",
    "    \n",
    "big_mat_mqtt = np.array(big_mat_mqtt)\n",
    "print(big_mat_mqtt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (m,n,p,q) : m: samples, n: window, p: line length, q: one hot characters in line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data and labels shape: (14194, 11, 82, 34) (14194,)\n",
      "data and labels shape mqtt: (1279, 11, 82, 34) (1279,)\n"
     ]
    }
   ],
   "source": [
    "print('data and labels shape:', big_mat.shape, y.shape)\n",
    "print('data and labels shape mqtt:', big_mat_mqtt.shape, y_mqtt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = big_mat.shape\n",
    "sh_mqtt = big_mat_mqtt.shape\n",
    "big_mat = big_mat.reshape(sh[0], -1)\n",
    "big_mat_mqtt = big_mat_mqtt.reshape(sh_mqtt[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14194, 30668) (14194,)\n",
      "(1279, 30668) (1279,)\n"
     ]
    }
   ],
   "source": [
    "# filter data matrix to ignore the nlt samples\n",
    "# big_mat = big_mat[y!=-1]\n",
    "# y = y[y!=-1]\n",
    "# big_mat_mqtt = big_mat_mqtt[y_mqtt!=-1]\n",
    "# y_mqtt = y_mqtt[y_mqtt!=-1]\n",
    "print(big_mat.shape, y.shape)\n",
    "print(big_mat_mqtt.shape, y_mqtt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels to one hot\n",
    "# labels = np.zeros((y.shape[0], c))\n",
    "# print(labels.shape)\n",
    "# for i in range(labels.shape[0]):\n",
    "#     labels[i][y[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0, samples : 11980\n",
      "label: 1, samples : 7\n",
      "label: 2, samples : 402\n",
      "label: 3, samples : 447\n",
      "label: 4, samples : 65\n",
      "label: 5, samples : 259\n",
      "label: 6, samples : 57\n",
      "label: 7, samples : 0\n",
      "label: 8, samples : 0\n",
      "label: 9, samples : 13\n",
      "label: 10, samples : 0\n",
      "label: 11, samples : 560\n",
      "label: 12, samples : 404\n",
      "!!!!!!!!!\n",
      "label_mqtt: 0, samples : 1079\n",
      "label_mqtt: 1, samples : 0\n",
      "label_mqtt: 2, samples : 88\n",
      "label_mqtt: 3, samples : 46\n",
      "label_mqtt: 4, samples : 0\n",
      "label_mqtt: 5, samples : 0\n",
      "label_mqtt: 6, samples : 0\n",
      "label_mqtt: 7, samples : 0\n",
      "label_mqtt: 8, samples : 0\n",
      "label_mqtt: 9, samples : 0\n",
      "label_mqtt: 10, samples : 0\n",
      "label_mqtt: 11, samples : 47\n",
      "label_mqtt: 12, samples : 19\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    print('label: {}, samples : {}'.format(i, y[y==i].shape[0]))\n",
    "print('!!!!!!!!!')\n",
    "for i in range(13):\n",
    "    print('label_mqtt: {}, samples : {}'.format(i, y_mqtt[y_mqtt==i].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch data and Model training for line classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from models import lstm_model, classifier\n",
    "from torch.nn import LSTM, Linear, ReLU, BatchNorm1d, Dropout, MaxPool1d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = big_mat.shape[1]\n",
    "batch_size = 1024\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "device = 'cuda'\n",
    "epochs = 100\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### big mat size: samples x features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 12774, test samples: 1420\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(big_mat, y, test_size=0.1, random_state=42)\n",
    "print('train samples: {}, test samples: {}'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train)) \n",
    "test_dataset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                    batch_size=batch_size, \n",
    "                                                    shuffle=True)\n",
    "            \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                    batch_size=batch_size, \n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(classifier, self).__init__()\n",
    "        self.fc1 = Linear(input_size, 512)\n",
    "        self.bn1 = BatchNorm1d(512)\n",
    "        self.r1 = ReLU()\n",
    "        self.d1 = Dropout(p=0.5)\n",
    "        self.m1 = MaxPool1d(3,stride = 1)\n",
    "        \n",
    "        self.fc2 = Linear(512, 128)\n",
    "        self.bn2 = BatchNorm1d(128)\n",
    "        self.r2 = ReLU()\n",
    "        self.d2 = Dropout(p=0.5)\n",
    "        self.m2 = MaxPool1d(3,stride = 1)\n",
    "        \n",
    "        self.fc3 = Linear(128, 32)\n",
    "#         self.d3 = Dropout(p=0.5)\n",
    "        self.r3 = ReLU()\n",
    "        self.fc4 = Linear(32,num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d1 ( self.r1( self.bn1 ( self.fc1(x) ) ) )\n",
    "#         x = self.m1(x)\n",
    "        x = self.d2 ( self.r2( self.bn2 ( self.fc2(x) ) ) )\n",
    "#         x = self.m2(x)\n",
    "        \n",
    "        x = self.r3(self.fc3(x))\n",
    "        out = self.fc4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = classifier(input_size, c).to(device)\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_current_loss_profile(train_loss_list, val_loss_list):\n",
    "    plt.plot(range(len(train_loss_list)), train_loss_list, label='train')\n",
    "    plt.plot(range(len(val_loss_list)), val_loss_list, label='val')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCHS:0] epoch_loss:2.063412207823533, val loss:1.1440152525901794, correct: 1277\n",
      "[EPOCHS:1] epoch_loss:1.0749380130034227, val loss:0.5437600314617157, correct: 1295\n",
      "[EPOCHS:2] epoch_loss:0.5037906376215128, val loss:0.382465198636055, correct: 1311\n",
      "[EPOCHS:3] epoch_loss:0.32042882763422453, val loss:0.276432141661644, correct: 1317\n",
      "[EPOCHS:4] epoch_loss:0.251029181938905, val loss:0.2202514410018921, correct: 1330\n",
      "[EPOCHS:5] epoch_loss:0.20299917115614965, val loss:0.17418739199638367, correct: 1350\n",
      "[EPOCHS:6] epoch_loss:0.1632799506187439, val loss:0.13618825748562813, correct: 1385\n",
      "[EPOCHS:7] epoch_loss:0.127483443571971, val loss:0.1034071110188961, correct: 1390\n",
      "[EPOCHS:8] epoch_loss:0.09849187903679334, val loss:0.07355990633368492, correct: 1398\n",
      "[EPOCHS:9] epoch_loss:0.07445830851793289, val loss:0.05631082318723202, correct: 1400\n",
      "[EPOCHS:10] epoch_loss:0.06124091979402762, val loss:0.04661058820784092, correct: 1401\n",
      "[EPOCHS:11] epoch_loss:0.049036783954271905, val loss:0.03727816417813301, correct: 1407\n",
      "[EPOCHS:12] epoch_loss:0.04164359288719984, val loss:0.03230726346373558, correct: 1408\n",
      "[EPOCHS:13] epoch_loss:0.03645715919824747, val loss:0.02862121630460024, correct: 1407\n",
      "[EPOCHS:14] epoch_loss:0.029917619692591522, val loss:0.027953004464507103, correct: 1409\n",
      "[EPOCHS:15] epoch_loss:0.026887009493433513, val loss:0.02418296318501234, correct: 1413\n",
      "[EPOCHS:16] epoch_loss:0.024097762428797208, val loss:0.02372186817228794, correct: 1412\n",
      "[EPOCHS:17] epoch_loss:0.021861216268287256, val loss:0.019526495598256588, correct: 1411\n",
      "[EPOCHS:18] epoch_loss:0.020585293165193155, val loss:0.017259457614272833, correct: 1412\n",
      "[EPOCHS:19] epoch_loss:0.0175147455615493, val loss:0.019564807415008545, correct: 1410\n",
      "[EPOCHS:20] epoch_loss:0.016944099217653275, val loss:0.018720339983701706, correct: 1411\n",
      "[EPOCHS:21] epoch_loss:0.0161840719385789, val loss:0.019165411591529846, correct: 1413\n",
      "[EPOCHS:22] epoch_loss:0.014927294391852159, val loss:0.018983937799930573, correct: 1413\n",
      "[EPOCHS:23] epoch_loss:0.013406414287881209, val loss:0.01718621188774705, correct: 1413\n",
      "[EPOCHS:24] epoch_loss:0.01272008872519319, val loss:0.016145355068147182, correct: 1413\n",
      "[EPOCHS:25] epoch_loss:0.012760122378285114, val loss:0.017318052239716053, correct: 1411\n",
      "[EPOCHS:26] epoch_loss:0.012762296944856644, val loss:0.017362949904054403, correct: 1411\n",
      "[EPOCHS:27] epoch_loss:0.01141076273499773, val loss:0.018916936591267586, correct: 1412\n",
      "[EPOCHS:28] epoch_loss:0.01150255213276698, val loss:0.01781293097883463, correct: 1411\n",
      "[EPOCHS:29] epoch_loss:0.010588807268784596, val loss:0.015426575671881437, correct: 1411\n",
      "[EPOCHS:30] epoch_loss:0.00958041649741622, val loss:0.015960611402988434, correct: 1412\n",
      "[EPOCHS:31] epoch_loss:0.010404379787639929, val loss:0.01679681148380041, correct: 1414\n",
      "[EPOCHS:32] epoch_loss:0.009778523065436345, val loss:0.020775727927684784, correct: 1412\n",
      "[EPOCHS:33] epoch_loss:0.009953420089844327, val loss:0.017296724021434784, correct: 1412\n",
      "[EPOCHS:34] epoch_loss:0.009411140201756587, val loss:0.016240633092820644, correct: 1413\n",
      "[EPOCHS:35] epoch_loss:0.008577420447881404, val loss:0.015369747299700975, correct: 1413\n",
      "[EPOCHS:36] epoch_loss:0.008685105193692904, val loss:0.012955129146575928, correct: 1414\n",
      "[EPOCHS:37] epoch_loss:0.007720357774255367, val loss:0.016504133120179176, correct: 1413\n",
      "[EPOCHS:38] epoch_loss:0.008397587180997316, val loss:0.016197845805436373, correct: 1413\n",
      "[EPOCHS:39] epoch_loss:0.007450737524777651, val loss:0.013455378822982311, correct: 1413\n",
      "[EPOCHS:40] epoch_loss:0.008046421759690229, val loss:0.01830886024981737, correct: 1411\n",
      "[EPOCHS:41] epoch_loss:0.007195055341491332, val loss:0.016238581389188766, correct: 1412\n",
      "[EPOCHS:42] epoch_loss:0.006582812441942783, val loss:0.016911718994379044, correct: 1413\n",
      "[EPOCHS:43] epoch_loss:0.006683893465938477, val loss:0.018714722245931625, correct: 1412\n",
      "[EPOCHS:44] epoch_loss:0.005509163879861052, val loss:0.016198703087866306, correct: 1414\n",
      "[EPOCHS:45] epoch_loss:0.006261039704370957, val loss:0.015563905704766512, correct: 1413\n",
      "[EPOCHS:46] epoch_loss:0.006243167373423393, val loss:0.013289929367601871, correct: 1412\n",
      "[EPOCHS:47] epoch_loss:0.005899222012465963, val loss:0.017159894108772278, correct: 1411\n",
      "[EPOCHS:48] epoch_loss:0.0057501213159412146, val loss:0.01822521910071373, correct: 1412\n",
      "[EPOCHS:49] epoch_loss:0.00453838029016669, val loss:0.01694339793175459, correct: 1412\n",
      "[EPOCHS:50] epoch_loss:0.005000869725615933, val loss:0.013902092818170786, correct: 1413\n",
      "[EPOCHS:51] epoch_loss:0.004953952112163489, val loss:0.01668691635131836, correct: 1414\n",
      "[EPOCHS:52] epoch_loss:0.004551741330382915, val loss:0.021205557510256767, correct: 1413\n",
      "[EPOCHS:53] epoch_loss:0.005391868207460413, val loss:0.019824763759970665, correct: 1412\n",
      "[EPOCHS:54] epoch_loss:0.005026238540617319, val loss:0.015746560879051685, correct: 1413\n",
      "[EPOCHS:55] epoch_loss:0.004812428315814871, val loss:0.013870003167539835, correct: 1413\n",
      "[EPOCHS:56] epoch_loss:0.004268114634144764, val loss:0.020986509509384632, correct: 1412\n",
      "[EPOCHS:57] epoch_loss:0.00389718278669394, val loss:0.012731832917779684, correct: 1416\n",
      "[EPOCHS:58] epoch_loss:0.0039280425184048135, val loss:0.013695152942091227, correct: 1414\n",
      "[EPOCHS:59] epoch_loss:0.0037171974455794464, val loss:0.017155498266220093, correct: 1412\n",
      "[EPOCHS:60] epoch_loss:0.0055183911552796, val loss:0.023954841308295727, correct: 1409\n",
      "[EPOCHS:61] epoch_loss:0.00456255183626826, val loss:0.020361019298434258, correct: 1411\n",
      "[EPOCHS:62] epoch_loss:0.004743334067125733, val loss:0.020046750083565712, correct: 1412\n",
      "[EPOCHS:63] epoch_loss:0.004709430522500322, val loss:0.018660699017345905, correct: 1410\n",
      "[EPOCHS:64] epoch_loss:0.004564332632491222, val loss:0.016463436651974916, correct: 1413\n",
      "[EPOCHS:65] epoch_loss:0.005773856107575389, val loss:0.012837949208915234, correct: 1416\n",
      "[EPOCHS:66] epoch_loss:0.004588150025273745, val loss:0.021311309188604355, correct: 1412\n",
      "[EPOCHS:67] epoch_loss:0.004976017400622368, val loss:0.022476552985608578, correct: 1410\n",
      "[EPOCHS:68] epoch_loss:0.00480836106894108, val loss:0.016865261364728212, correct: 1412\n",
      "[EPOCHS:69] epoch_loss:0.003920087662453835, val loss:0.014863041462376714, correct: 1413\n",
      "[EPOCHS:70] epoch_loss:0.0053932686658719415, val loss:0.017064518062397838, correct: 1414\n",
      "[EPOCHS:71] epoch_loss:0.006011004882076612, val loss:0.01611978095024824, correct: 1413\n",
      "[EPOCHS:72] epoch_loss:0.005458808915976148, val loss:0.02131187543272972, correct: 1412\n",
      "[EPOCHS:73] epoch_loss:0.006306650528970819, val loss:0.0193165997043252, correct: 1413\n",
      "[EPOCHS:74] epoch_loss:0.004931929037691309, val loss:0.01995069347321987, correct: 1413\n",
      "[EPOCHS:75] epoch_loss:0.005103085852729587, val loss:0.01754529168829322, correct: 1412\n",
      "[EPOCHS:76] epoch_loss:0.00439180492853316, val loss:0.01790878875181079, correct: 1414\n",
      "[EPOCHS:77] epoch_loss:0.0045705668341654996, val loss:0.019093082286417484, correct: 1413\n",
      "[EPOCHS:78] epoch_loss:0.003784031356469943, val loss:0.01767469011247158, correct: 1413\n",
      "[EPOCHS:79] epoch_loss:0.0038999841870883335, val loss:0.014601567294448614, correct: 1414\n",
      "[EPOCHS:80] epoch_loss:0.0038658458327587982, val loss:0.01376444660127163, correct: 1413\n",
      "[EPOCHS:81] epoch_loss:0.004264991855821931, val loss:0.013239643070846796, correct: 1413\n",
      "[EPOCHS:82] epoch_loss:0.0034557892582737482, val loss:0.020117403008043766, correct: 1414\n",
      "[EPOCHS:83] epoch_loss:0.0037344660690555777, val loss:0.016844263765960932, correct: 1413\n",
      "[EPOCHS:84] epoch_loss:0.00316646471261405, val loss:0.014179656747728586, correct: 1414\n",
      "[EPOCHS:85] epoch_loss:0.00323878382690824, val loss:0.01649003801867366, correct: 1412\n",
      "[EPOCHS:86] epoch_loss:0.0031368987312397133, val loss:0.018663653638213873, correct: 1411\n",
      "[EPOCHS:87] epoch_loss:0.0031376984239054415, val loss:0.015995503403246403, correct: 1411\n",
      "[EPOCHS:88] epoch_loss:0.002556616400117771, val loss:0.01807283889502287, correct: 1412\n",
      "[EPOCHS:89] epoch_loss:0.002499791865165417, val loss:0.017268003430217505, correct: 1413\n",
      "[EPOCHS:90] epoch_loss:0.0023303851664352873, val loss:0.016547316685318947, correct: 1415\n",
      "[EPOCHS:91] epoch_loss:0.0025607947116860976, val loss:0.015544152352958918, correct: 1414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCHS:92] epoch_loss:0.002542281158429642, val loss:0.01830102689564228, correct: 1414\n",
      "[EPOCHS:93] epoch_loss:0.002521093003451824, val loss:0.01871885033324361, correct: 1413\n",
      "[EPOCHS:94] epoch_loss:0.0024703514869683064, val loss:0.020333504769951105, correct: 1413\n",
      "[EPOCHS:95] epoch_loss:0.001995839662133501, val loss:0.016617147251963615, correct: 1413\n",
      "[EPOCHS:96] epoch_loss:0.0020511299998571095, val loss:0.01732051931321621, correct: 1415\n",
      "[EPOCHS:97] epoch_loss:0.0024336346675856756, val loss:0.01968430122360587, correct: 1414\n",
      "[EPOCHS:98] epoch_loss:0.0021678145276382565, val loss:0.0193395153619349, correct: 1413\n",
      "[EPOCHS:99] epoch_loss:0.002727974528590074, val loss:0.021816673688590527, correct: 1413\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf.train()\n",
    "train_loss_total = []\n",
    "val_loss_total = []\n",
    "for e in range(epochs):\n",
    "    running_epoch_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in train_loader:\n",
    "        counter+=1\n",
    "        data, target = data.to(device).float(), target.to(device).long()\n",
    "        clf.zero_grad()\n",
    "        output = clf(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_epoch_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(clf.parameters(), clip) # need this??\n",
    "        optimizer.step()\n",
    "#     print('correct first: ', correct.item())\n",
    "    clf.eval()\n",
    "    running_val_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device).long()\n",
    "        output = clf(data)\n",
    "        \n",
    "        correct+=torch.sum(torch.argmax(output, dim=1)==target)\n",
    "        \n",
    "        val_loss = criterion(output, target)\n",
    "        running_val_loss+=val_loss.item()\n",
    "    train_loss_total.append(running_epoch_loss/len(train_loader))\n",
    "    val_loss_total.append(running_val_loss/len(test_loader))\n",
    "    clf.train()\n",
    "    print('[EPOCHS:{}] epoch_loss:{}, val loss:{}, correct: {}'.format(e, train_loss_total[-1], val_loss_total[-1], correct))\n",
    "plot_current_loss_profile(train_loss_total, val_loss_total)\n",
    "torch.save(clf.state_dict(), 'classifier_nway.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas\n",
    "\n",
    "1. Autoencoders to latents?\n",
    "<br>\n",
    "2. Embedding matrix?\n",
    "<br>\n",
    "3. reduce sparsity\n",
    "<br>\n",
    "4. Txt2pic: converts each char in each line of RFC into a pixel value. \n",
    "<br>\n",
    "\n",
    "### AI:\n",
    "post processing : break RFCs into separate blocks and label the dominant. Plot the CM for blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MQTT exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test samples: 1279\n",
      "[[1077    0    0    1    0    1    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1   21   32   31    0    0    1    0    2]\n",
      " [   4    0    0   37    1    0    1    0    0    3]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0   47    0]\n",
      " [  15    0    0    0    0    0    0    0    0    4]]\n"
     ]
    }
   ],
   "source": [
    "A, X_test, ya, y_test = train_test_split(big_mat_mqtt, y_mqtt, test_size=0, random_state=42)\n",
    "print('test samples: {}'.format(A.shape[0]))\n",
    "\n",
    "mqtttest = TensorDataset(torch.Tensor(A), torch.Tensor(ya)) \n",
    "# test_dataset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "mqtttest_loader = torch.utils.data.DataLoader(dataset=mqtttest,\n",
    "                                                    batch_size=1024, \n",
    "                                                    shuffle=True)\n",
    "\n",
    "clf = classifier(input_size, c).to(device)\n",
    "clf.load_state_dict(torch.load('classifier_nway.pth'))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "r = 6 # strdef\n",
    "miscls = []\n",
    "correct_classified = []\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for data, target in mqtttest_loader:\n",
    "    data, target = data.to(device), target.to(device).long()\n",
    "    output = clf(data)\n",
    "    \n",
    "    _y_pred = torch.argmax(output, dim=1).cpu().detach().numpy().tolist()\n",
    "    y_pred.extend(_y_pred)\n",
    "    \n",
    "    _target = target.cpu().detach().numpy().tolist()\n",
    "    y_true.extend(_target)\n",
    "    \n",
    "    for i in range(len(_y_pred)):\n",
    "        if _target[i]==r and _y_pred[i]!=r:\n",
    "            miscls.append(data.cpu().detach().numpy()[i])\n",
    "        elif _target[i]==r and _y_pred[i]==r:\n",
    "            correct_classified.append(data.cpu().detach().numpy()[i])\n",
    "    \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# df_cm = pd.DataFrame(cm, range(9), range(9))\n",
    "# sns.set(df_cm, annnot=True, annot_kws={\"size\": 10}, fmt='g') # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-18d587a9dc61>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-18d587a9dc61>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    label_mqtt: 0, samples : 1528\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "label_mqtt: 0, samples : 1528\n",
    "label_mqtt: 1, samples : 3\n",
    "label_mqtt: 2, samples : 97\n",
    "label_mqtt: 3, samples : 48\n",
    "label_mqtt: 4, samples : 0\n",
    "label_mqtt: 5, samples : 0\n",
    "label_mqtt: 6, samples : 0\n",
    "label_mqtt: 7, samples : 0\n",
    "label_mqtt: 8, samples : 0\n",
    "label_mqtt: 9, samples : 0\n",
    "label_mqtt: 10, samples : 0\n",
    "label_mqtt: 11, samples : 47\n",
    "label_mqtt: 12, samples : 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total target class misclassified',len(miscls))\n",
    "\n",
    "def one_hot_to_idx(t):\n",
    "    r = []\n",
    "    for i in t:\n",
    "        b = np.where(i==1)[0][0]\n",
    "        r.append(b)\n",
    "    return np.array(r)\n",
    "\n",
    "def idx_to_charr(v):\n",
    "    r = []\n",
    "    for i in v:\n",
    "        r.append(idx_to_char[i])\n",
    "    return r\n",
    "\n",
    "middleelement = 11//2\n",
    "for i,e in enumerate(miscls):\n",
    "    r = one_hot_to_idx(e.reshape(5, 82, 34)[middleelement])\n",
    "    print(i)\n",
    "    print(''.join(idx_to_charr(r)))\n",
    "    print('\\n---------next line-----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miscls[4][middleelement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2131:\n",
    "# 'onr_rfcclass_nlt' : 0, \n",
    "# 'onr_rfcclass_strdef' : 1, \n",
    "# 'onr_rfcclass_msgStructure' : 2,\n",
    "# 'onr_rfcclass_dataflow' : 3,\n",
    "# 'onr_rfcclass_topologyDiag' : 4,\n",
    "# 'onr_rfcclass_table' : 5,\n",
    "# 'onr_rfcclass_stateTD' : 6,\n",
    "# 'onr_rfcclass_cs' : 7,\n",
    "# 'onr_rfcclass_protocolLayerDiag' : 8,\n",
    "# 'onr_rfcclass_caption' : 9,\n",
    "# 'onr_rfcclass_headers' : 10,\n",
    "# 'onr_rfcclass_toc' : 11,\n",
    "# 'onr_rfcclass_lex_spec' : 12\n",
    "\n",
    "# test samples: 2276\n",
    "#  [1888    0    0    0    0    0    0    0    0    0]\n",
    "#  [   0    0    0    0    0    0    0    0    0    0]\n",
    "#  [   0    0   33    1    0    2    0    0    0    0] msgstructure\n",
    "#  [   1    0   16   55    0    0    0    0    0    0] dataflow\n",
    "#  [   0    0    0    0    0    0    0    0    0    0]\n",
    "#  [ 106    2   11   43    0   16    0    0    0    2] table\n",
    "#  [   2    0    2    2    7    1    0    0   29    0] statediag\n",
    "#  [   2    3    0    2    0    0    0    0    0    6] captions -- also not standardized\n",
    "#  [   0    0    0    0    0    0    0    0   44    0] table of contents\n",
    "#  [   0    0    0    0    0    0    0    0    0    0]\n",
    "\n",
    "\n",
    "# [[ 0  0  0  0  0  0  0  0  0]\n",
    "#  [ 0 35  1  0  0  0  0  0  0]\n",
    "#  [ 0  6 47 13  0  0  0  0  6]\n",
    "#  [ 0  0  0  0  0  0  0  0  0]\n",
    "#  [11 20 59  8 39  2  0  5 36]\n",
    "#  [ 0 11  1  2  0  0  0 29  0]\n",
    "#  [ 0  2  0  0  0  0  0  1 10]\n",
    "#  [ 0  0  0  0  0  0  0 44  0]\n",
    "#  [ 0  0  0  0  0  0  0  0  0]]\n",
    "\n",
    "\n",
    "# label_mqtt: 0, samples : 1888\n",
    "# label_mqtt: 1, samples : 0\n",
    "# label_mqtt: 2, samples : 36\n",
    "# label_mqtt: 3, samples : 72\n",
    "# label_mqtt: 4, samples : 0\n",
    "# label_mqtt: 5, samples : 180\n",
    "# label_mqtt: 6, samples : 43\n",
    "# label_mqtt: 7, samples : 0\n",
    "# label_mqtt: 8, samples : 0\n",
    "# label_mqtt: 9, samples : 13\n",
    "# label_mqtt: 10, samples : 0\n",
    "# label_mqtt: 11, samples : 44\n",
    "# label_mqtt: 12, samples : 0\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "# 1661: window 2\n",
    "# [[2511    0    2    8    0    6    0    9    6]\n",
    "#  [   3    0    2    7    5    0    0    0    1] strdef\n",
    "#  [  34    0   63   16    0    6    0    0    0]\n",
    "#  [   0    0    0    0    0    0    0    0    0]\n",
    "#  [   0    0    0    0    0    0    0    0    0]\n",
    "#  [  29    0    3   39    0    5    1    0    4] table\n",
    "#  [   0    0    7    6    0    0    1    0    0] stateTD\n",
    "#  [   7    0    0    0    0    0    0   39    0]\n",
    "#  [   0    0    0    0    0    0    0    0    0]]\n",
    "\n",
    "\n",
    "# label_mqtt: 0, samples : 2537\n",
    "# label_mqtt: 1, samples : 18\n",
    "# label_mqtt: 2, samples : 119\n",
    "# label_mqtt: 3, samples : 0\n",
    "# label_mqtt: 4, samples : 0\n",
    "# label_mqtt: 5, samples : 81\n",
    "# label_mqtt: 6, samples : 14\n",
    "# label_mqtt: 7, samples : 0\n",
    "# label_mqtt: 8, samples : 0\n",
    "# label_mqtt: 9, samples : 0\n",
    "# label_mqtt: 10, samples : 0\n",
    "# label_mqtt: 11, samples : 46\n",
    "# label_mqtt: 12, samples : 0\n",
    "\n",
    "# strdef : very few examples (1661, mqtt) and both are wildly different\n",
    "# toc now fixed\n",
    "# table : postprocessing fixes\n",
    "# stateTD : very few examples and very varied\n",
    "\n",
    "\n",
    "# [[ 0  0  5  4  0  0  0  9] strdef\n",
    "#  [ 0 79 30  1  1  0  0  8] msgstructure\n",
    "#  [ 0  0  0  0  0  0  0  0]\n",
    "#  [ 0  0  0  0  0  0  0  0]\n",
    "#  [ 1  1 39  0 25  1  0 14] \n",
    "#  [ 0  3 10  0  1  0  0  0]\n",
    "#  [ 0  0  0  0  0  0 46  0]\n",
    "#  [ 0  0  0  0  0  0  0  0]]\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# test samples: 2675\n",
    "# [[2241    2    0   21    0   10    0    0    3]\n",
    "#  [   0    0    0    0    0    0    0    0    0]\n",
    "#  [  11    0   55  137   23    2    2    0    1]\n",
    "#  [   0    0    1   69    8    0    0    0    2]\n",
    "#  [   0    0    2   11    1    0    0    0    1]\n",
    "#  [   0    0    0    0    0    0    0    0    0]\n",
    "#  [   0    0    0    0    0    0    0    0    0]\n",
    "#  [   0    0    0    0    0    0    0   72    0]\n",
    "#  [   0    0    0    0    0    0    0    0    0]]\n",
    "\n",
    "# label_mqtt: 0, samples : 2277\n",
    "# label_mqtt: 0, samples : 0\n",
    "# label_mqtt: 1, samples : 231\n",
    "# label_mqtt: 2, samples : 80\n",
    "# label_mqtt: 3, samples : 15\n",
    "# label_mqtt: 4, samples : 0\n",
    "# label_mqtt: 5, samples : 0\n",
    "# label_mqtt: 6, samples : 0\n",
    "# label_mqtt: 7, samples : 0\n",
    "# label_mqtt: 8, samples : 0\n",
    "# label_mqtt: 9, samples : 0\n",
    "# label_mqtt: 10, samples : 72\n",
    "# label_mqtt: 11, samples : 0\n",
    "# label_mqtt: 12, samples : 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:onr]",
   "language": "python",
   "name": "conda-env-onr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
